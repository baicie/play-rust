use crate::config::PostgresSinkConfig;
use async_trait::async_trait;
use dbsync_core::{
    connector::{ConnectorConfig, DataBatch, Sink},
    error::{Error, Result},
};
use sqlx::postgres::{PgPool, PgPoolOptions};
use sqlx::types::time::PrimitiveDateTime;
use sqlx::types::BigDecimal;
use sqlx::Row;
use std::collections::HashMap;
use std::str::FromStr;
use time::macros::format_description;
use tracing::info;

#[derive(Clone)]
pub struct PostgresSink {
    config: PostgresSinkConfig,
    pool: Option<PgPool>,
    source_schema: String,
}

impl PostgresSink {
    pub fn new(config: ConnectorConfig) -> Result<Self> {
        let source_schema = config
            .properties
            .get("source_schema")
            .and_then(|v| v.as_str())
            .ok_or_else(|| Error::Config("source_schema not provided".into()))?;

        let config = PostgresSinkConfig::from_json(serde_json::Value::Object(
            serde_json::Map::from_iter(config.properties.clone()),
        ))?;

        Ok(Self {
            config,
            pool: None,
            source_schema: source_schema.to_string(),
        })
    }

    async fn verify_table(&self, pool: &PgPool) -> Result<()> {
        let table = &self.config.table;

        let columns = sqlx::query(
            "SELECT column_name, data_type 
             FROM information_schema.columns 
             WHERE table_name = $1",
        )
        .bind(table)
        .fetch_all(pool)
        .await
        .map_err(|e| Error::Connection(e.to_string()))?;

        info!("Table {} structure:", table);
        for row in columns {
            let column_name: String = row.get("column_name");
            let data_type: String = row.get("data_type");
            info!("  Column: {} ({})", column_name, data_type);
        }

        Ok(())
    }

    async fn ensure_table_exists(&self, pool: &PgPool) -> Result<()> {
        let table = &self.config.table;

        // 先删除已存在的表
        info!("Dropping existing table if exists...");
        let drop_table = format!("DROP TABLE IF EXISTS {}", table);
        sqlx::query(&drop_table)
            .execute(pool)
            .await
            .map_err(|e| Error::Connection(format!("Failed to drop table: {}", e)))?;

        // 使用源表结构创建新表
        info!("Creating table using source schema...");
        let schema = self
            .source_schema
            .split("CREATE TABLE `source_table`")
            .nth(1)
            .and_then(|s| Some(s.trim_matches(|c| c == ' ' || c == '\n')))
            .map(|s| {
                s.replace("`", "\"")
                    .replace(" AUTO_INCREMENT=100001", "")
                    .replace("AUTO_INCREMENT", "GENERATED BY DEFAULT AS IDENTITY")
                    .replace("ENGINE=InnoDB", "")
                    .replace("DEFAULT CHARSET=utf8mb4", "")
                    .replace("COLLATE=utf8mb4_0900_ai_ci", "")
                    .replace("tinyinteger", "SMALLINT")
                    .replace("tinyint", "SMALLINT")
                    .replace("bigint", "BIGINT")
                    .replace("int", "INTEGER")
                    .replace("varchar", "VARCHAR")
                    .replace("datetime", "TIMESTAMP")
                    .replace("decimal", "NUMERIC")
                    .trim()
                    .to_string()
            })
            .ok_or_else(|| Error::Config("Invalid source schema".into()))?;

        let create_table = format!("CREATE TABLE {} {}", table, schema);
        info!("Creating table: {}", create_table);

        sqlx::query(&create_table)
            .execute(pool)
            .await
            .map_err(|e| Error::Connection(format!("Failed to create table: {}", e)))?;

        self.verify_table(pool).await?;
        Ok(())
    }
}

#[async_trait]
impl Sink for PostgresSink {
    fn clone_box(&self) -> Box<dyn Sink> {
        Box::new(self.clone())
    }

    async fn init(&mut self) -> Result<()> {
        let url = &self.config.url;
        info!("Connecting to PostgreSQL database: {}", url);

        let pool = PgPoolOptions::new()
            .max_connections(self.config.max_connections as u32)
            .connect(url)
            .await
            .map_err(|e| Error::Connection(e.to_string()))?;

        // 在初始化时创建表
        let table = &self.config.table;
        info!("Dropping existing table if exists...");
        let drop_table = format!("DROP TABLE IF EXISTS {}", table);
        sqlx::query(&drop_table)
            .execute(&pool)
            .await
            .map_err(|e| Error::Connection(format!("Failed to drop table: {}", e)))?;

        info!("Creating table using source schema...");
        let schema = self
            .source_schema
            .split("CREATE TABLE `source_table`")
            .nth(1)
            .and_then(|s| Some(s.trim_matches(|c| c == ' ' || c == '\n')))
            .map(|s| {
                s.replace("`", "\"")
                    .replace(" AUTO_INCREMENT=100001", "")
                    .replace("AUTO_INCREMENT", "GENERATED BY DEFAULT AS IDENTITY")
                    .replace("ENGINE=InnoDB", "")
                    .replace("DEFAULT CHARSET=utf8mb4", "")
                    .replace("COLLATE=utf8mb4_0900_ai_ci", "")
                    .replace("tinyinteger", "SMALLINT")
                    .replace("tinyint", "SMALLINT")
                    .replace("bigint", "BIGINT")
                    .replace("int", "INTEGER")
                    .replace("varchar", "VARCHAR")
                    .replace("datetime", "TIMESTAMP")
                    .replace("decimal", "NUMERIC")
                    .trim()
                    .to_string()
            })
            .ok_or_else(|| Error::Config("Invalid source schema".into()))?;

        let create_table = format!("CREATE TABLE {} {}", table, schema);
        info!("Creating table: {}", create_table);

        sqlx::query(&create_table)
            .execute(&pool)
            .await
            .map_err(|e| Error::Connection(format!("Failed to create table: {}", e)))?;

        self.pool = Some(pool);
        Ok(())
    }

    async fn write_batch(&mut self, batch: DataBatch) -> Result<()> {
        let pool = self
            .pool
            .as_ref()
            .ok_or_else(|| Error::Connection("Not connected".into()))?;
        let table = &self.config.table;

        // 获取表的列类型信息
        let column_types = sqlx::query(
            "SELECT column_name, data_type 
             FROM information_schema.columns 
             WHERE table_name = $1",
        )
        .bind(table)
        .fetch_all(pool)
        .await
        .map_err(|e| Error::Connection(e.to_string()))?;

        let type_map: HashMap<String, String> = column_types
            .into_iter()
            .map(|row| {
                (
                    row.get::<String, _>("column_name"),
                    row.get::<String, _>("data_type"),
                )
            })
            .collect();

        // 从第一条记录获取列名
        if let Some(record) = batch.records.first() {
            let columns = record
                .fields
                .keys()
                .map(|s| format!("\"{}\"", s))
                .collect::<Vec<_>>()
                .join(", ");
            let placeholders = (1..=record.fields.len())
                .map(|i| format!("${}", i))
                .collect::<Vec<_>>()
                .join(", ");
            let query = format!(
                "INSERT INTO {} ({}) VALUES ({})",
                table, columns, placeholders
            );

            // 批量处理记录
            for record in batch.records {
                let mut query = sqlx::query(&query);

                // 收集所有的值
                let mut values = Vec::new();
                for (name, value) in record.fields.iter() {
                    match type_map.get(name).map(|s| s.as_str()) {
                        Some("timestamp") | Some("timestamp without time zone") => match value {
                            serde_json::Value::String(s) => {
                                if s == "NULL" {
                                    query = query.bind(None::<PrimitiveDateTime>);
                                } else {
                                    let format = format_description!(
                                        "[year]-[month]-[day] [hour]:[minute]:[second]"
                                    );
                                    let dt = PrimitiveDateTime::parse(s, &format).ok();
                                    query = query.bind(dt);
                                }
                            }
                            serde_json::Value::Number(_) => {
                                // 对于数字类型的时间戳，也转为 NULL
                                query = query.bind(None::<PrimitiveDateTime>);
                            }
                            _ => query = query.bind(None::<PrimitiveDateTime>),
                        },
                        Some("numeric") | Some("decimal") => match value {
                            serde_json::Value::Number(n) => {
                                let num = BigDecimal::from_str(&n.to_string()).unwrap_or_default();
                                query = query.bind(num);
                            }
                            serde_json::Value::String(s) => {
                                let num = BigDecimal::from_str(s).unwrap_or_default();
                                query = query.bind(num);
                            }
                            _ => query = query.bind(BigDecimal::default()),
                        },
                        Some("bigint") => match value {
                            serde_json::Value::Number(n) => {
                                query = query.bind(n.as_i64().unwrap_or(0))
                            }
                            serde_json::Value::String(s) => {
                                query = query.bind(s.parse::<i64>().unwrap_or(0))
                            }
                            _ => query = query.bind(0i64),
                        },
                        Some("integer") | Some("smallint") => match value {
                            serde_json::Value::String(s) => {
                                if s == "NULL" {
                                    query = query.bind(None::<i16>);
                                } else {
                                    query = query.bind(Some(s.parse::<i16>().unwrap_or(0)));
                                }
                            }
                            serde_json::Value::Number(n) => {
                                query = query.bind(Some(n.as_i64().map(|i| i as i16).unwrap_or(0)));
                            }
                            _ => query = query.bind(None::<i16>),
                        },
                        _ => match value {
                            serde_json::Value::String(s) => query = query.bind(s.as_str()),
                            _ => query = query.bind(""),
                        },
                    }
                    values.push(format!("{:?}", value));
                }

                // 打印完整的 SQL 语句
                info!("Executing with values: [{}]", values.join(", "));

                query
                    .execute(pool)
                    .await
                    .map_err(|e| Error::Write(e.to_string()))?;
            }
        }

        Ok(())
    }

    async fn commit(&mut self) -> Result<()> {
        Ok(())
    }

    async fn close(&mut self) -> Result<()> {
        if let Some(pool) = self.pool.take() {
            info!("Closing PostgreSQL connection");
            pool.close().await;
        }
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use dbsync_core::connector::Record;
    use serde_json::json;
    use std::collections::HashMap;

    async fn setup_test_db() -> PgPool {
        let url = std::env::var("TEST_POSTGRES_URL").unwrap_or("".to_string());

        PgPoolOptions::new()
            .max_connections(5)
            .connect(&url)
            .await
            .expect("Failed to connect to PostgreSQL")
    }

    #[tokio::test]
    async fn test_write_batch() {
        let pool = setup_test_db().await;

        // 创建测试表
        sqlx::query(
            "CREATE TABLE IF NOT EXISTS test_sink (
                id INT,
                name VARCHAR(255),
                age INT
            )",
        )
        .execute(&pool)
        .await
        .unwrap();

        // 创建并初始化 sink
        let config = ConnectorConfig {
            name: "test_sink".to_string(),
            connector_type: "postgres".to_string(),
            properties: HashMap::from_iter(vec![
                (
                    "url".to_string(),
                    json!("postgres://postgres:password@localhost:5432/test"),
                ),
                ("table".to_string(), json!("test_sink")),
                ("max_connections".to_string(), json!(5)),
            ]),
        };

        let mut sink = PostgresSink::new(config).unwrap();
        sink.init().await.unwrap();

        // 准备测试数据
        let batch = DataBatch {
            records: vec![
                Record {
                    fields: HashMap::from_iter(vec![
                        ("id".to_string(), json!(1)),
                        ("name".to_string(), json!("Alice")),
                        ("age".to_string(), json!(20)),
                    ]),
                },
                Record {
                    fields: HashMap::from_iter(vec![
                        ("id".to_string(), json!(2)),
                        ("name".to_string(), json!("Bob")),
                        ("age".to_string(), json!(25)),
                    ]),
                },
            ],
        };

        // 写入数据
        sink.write_batch(batch).await.unwrap();

        // 写入的数据
        let rows: Vec<(i32, String, i32)> = sqlx::query_as("SELECT id, name, age FROM test_sink")
            .fetch_all(&pool)
            .await
            .unwrap();

        assert_eq!(rows.len(), 2);
        assert_eq!(rows[0], (1, "Alice".to_string(), 20));
        assert_eq!(rows[1], (2, "Bob".to_string(), 25));

        // 清理测试数据
        sqlx::query("DROP TABLE test_sink")
            .execute(&pool)
            .await
            .unwrap();
    }
}
